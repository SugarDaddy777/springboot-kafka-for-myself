server:
  port: 9090

#日志配置
logging:
  config: classpath:log/log4j2-spring.xml

redisson:
  lockWatchdogTimeout: 15000
  connectionMinimumIdleSize : 10

mybatis:
  mapper-locations: classpath:mapper/**/*.xml
  type-aliases-package: com.leelen.crm.shop.entity.generation,com.leelen.crm.shop.entity.vo,com.leelen.crm.shop.entity.request
  config-location: classpath:mybatis/mybatis-config.xml

spring:
  datasource:
    url: jdbc:mysql://10.173.173.158:3306/leelen_crm_shop?useUnicode=true&characterEncoding=utf-8&useSSL=false&serverTimezone=GMT%2B8&tinyInt1isBit=false
    username: root
    password: root123
    driver-class-name: com.mysql.cj.jdbc.Driver
    type: com.alibaba.druid.pool.DruidDataSource
    druid:
      # 配置初始化大小、最小、最大 (通常来说，只需要修改initialSize、minIdle、maxActive)
      initial-size: 5
      min-idle: 5
      max-active: 20
      # 配置获取连接等待超时的时间
      max-wait: 10000
      # 配置间隔多久才进行一次检测，检测需要关闭的空闲连接，单位是毫秒
      time-between-eviction-runs-millis: 600000
      # 配置一个连接在池中最小生存的时间，单位是毫秒
      min-evictable-idle-time-millis: 300000
      validation-query: SELECT 1 FROM DUAL
      test-while-idle: true
      test-on-borrow: false
      test-on-return: false
      # 打开PSCache，并且指定每个连接上PSCache的大小
      pool-prepared-statements: false
      max-pool-prepared-statement-per-connection-size: 20
      # 配置监控统计拦截的filters，去掉后监控界面sql无法统计，'wall'用于防火墙
      filters: stat,wall,slf4j
      # 通过connectProperties属性来打开mergeSql功能；慢SQL记录
      connection-properties: druid.stat.mergeSql=true;druid.stat.slowSqlMillis=5000
      #useGlobalDataSourceStat: true # 合并多个DruidDataSource的监控数据
      # 用了shardingjdbc后，上面的不再生效，也容易理解，因为他不知道你有几个数据源，而下面的配置和数据源无关
      web-stat-filter:
        enabled: true
        url-pattern: "/*"
        exclusions: "*.js,*.gif,*.jpg,*.bmp,*.png,*.css,*.ico,/druid/*"
      # 配置DruidStatViewServlet
      stat-view-servlet:
        enabled: true
        url-pattern: "/druid/*"
        # IP白名单(没有配置或者为空，则允许所有访问)
        allow:
        # IP黑名单 (存在共同时，deny优先于allow)
        #deny: 192.168.1.100
        #  禁用HTML页面上的“Reset All”功能
        reset-enable: false
        # 登录名
        login-username: ENC(xpZqjN8GFIjaOPG7aiuhjQ==)
        # 登录密码
        login-password: ENC(otXZFZOnzEcmsK4epgHIlA==)
  kafka:
    bootstrap-servers: 159.75.2.217:9092
    consumer:
      # 配置消费者消息offset是否自动重置(消费者重连会能够接收最开始的消息)
      auto-offset-reset: earliest
    producer:
      value-serializer: org.apache.kafka.common.serialization.StringSerializer
      retries: 3  #  重试次数
  redis:
    database: 0
    host: 159.75.2.217
    port: 6380
    timeout: 10000

kafka:
  topic:
    my-topic: my-topic